# Data-Engineering-Projects
Design data models, build data warehouses and data lakes, automate data pipelines, and work with massive datasets

# Distributed-Systems 

### Data Modeling with Postgres

- Model user activity data to create a database and ETL pipeline in Postgres for a music steaming app

### Data Modeling with Cassandra

- Model event data to create a non-relational database and ETL pipeline for a music streaming app

### Data Warehouse

- Build an ETL piepline that extracts data from S3, stages them in Redshift, and transform data into a set of dimensional tables

### Data Lake

- Build a data lake and an ETL pipeline in Sparks that loads data from S3, processes the data into analytic tables, and loads them back into S3

### Data Pipelines with Airflow

- Creating and automating a set of data pipelines with Apache Airflow, monitoring and debugging  pipelines

### Data Engineering Capstone

- Work with more than 1 million rows of dataset, and create a data pipeline using Apache Spark